{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5550cd-b460-465e-bd0c-537af1609743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Promotion Lift Modeling with Neural Networks\n",
    "# Topic: Non-linear promotional effects, cannibalization, ROI estimation\n",
    "# Input: Sales time-series with promotions, channels, timing, discounts\n",
    "# Output: Baseline vs uplift predictions, interaction effects, ROI metrics\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d56e07-1411-4180-ae8b-9953605025f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1. CONFIG & CONSTANTS ====\n",
    "\n",
    "DATA_PATH = \"synthetic_promo_data.csv\"\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SPLIT = 0.15\n",
    "\n",
    "# Model hyperparameters\n",
    "NN_HIDDEN_UNITS = [64, 32, 16]\n",
    "NN_LEARNING_RATE = 0.001\n",
    "NN_EPOCHS = 100\n",
    "NN_BATCH_SIZE = 32\n",
    "\n",
    "# Business parameters\n",
    "PRODUCT_COST = 15.0  # $ per unit\n",
    "MIN_DISCOUNT_THRESHOLD = 0.05  # 5% minimum discount to trigger promo\n",
    "CANNIBALIZATION_THRESHOLD = -0.10  # -10% = cannibalization signal\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51b4353-a8e9-4f86-bc8e-d3f2f40a8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2. SYNTHETIC DATA GENERATION ====\n",
    "\n",
    "def generate_promotion_data(n_rows=500):\n",
    "    \"\"\"\n",
    "    Create realistic promotional sales data with:\n",
    "    - Baseline demand (day-of-week, trend)\n",
    "    - Promotional effects (discount-driven lift)\n",
    "    - Channel differences (online vs. retail)\n",
    "    - Interaction effects (discount × channel × timing)\n",
    "    - Cannibalization (weekend discount cannibalizes nearby weekday sales)\n",
    "    \"\"\"\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    data = {\n",
    "        'day_of_week': np.random.randint(0, 7, n_rows),\n",
    "        'hour': np.random.randint(0, 24, n_rows),\n",
    "        'channel': np.random.choice(['online', 'retail'], n_rows),\n",
    "        'discount_pct': np.random.uniform(0, 50, n_rows),\n",
    "        'is_weekend': np.random.choice([0, 1], n_rows),\n",
    "        'competitor_discount': np.random.uniform(0, 40, n_rows),\n",
    "        'inventory_level': np.random.uniform(0.2, 1.0, n_rows),\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Baseline: day-of-week pattern\n",
    "    dow_baseline = np.array([80, 85, 90, 95, 120, 110, 100])\n",
    "    df['baseline_demand'] = df['day_of_week'].map(lambda x: dow_baseline[x])\n",
    "    \n",
    "    # Discount lift (non-linear: diminishing returns at high discounts)\n",
    "    df['discount_effect'] = df['discount_pct'] * 0.8 - (df['discount_pct'] ** 2) * 0.005\n",
    "    \n",
    "    # Channel interaction: online responds stronger to discounts\n",
    "    channel_multiplier = np.where(df['channel'] == 'online', 1.5, 1.0)\n",
    "    df['channel_interaction'] = df['discount_effect'] * channel_multiplier\n",
    "    \n",
    "    # Weekend cannibalization: high weekend discount hurts future demand\n",
    "    df['cannibalization'] = np.where(\n",
    "        (df['is_weekend'] == 1) & (df['discount_pct'] > 20),\n",
    "        -0.15 * df['discount_pct'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Competitive pressure (reduce lift if competitor also discounts)\n",
    "    df['competitive_effect'] = -0.3 * np.minimum(df['discount_pct'], df['competitor_discount'])\n",
    "    \n",
    "    # Total sales (baseline + promotional + cannibalization)\n",
    "    df['sales_units'] = (\n",
    "        df['baseline_demand'] +\n",
    "        df['channel_interaction'] +\n",
    "        df['cannibalization'] +\n",
    "        df['competitive_effect'] +\n",
    "        np.random.normal(0, 5, n_rows)  # noise\n",
    "    )\n",
    "    \n",
    "    df['sales_units'] = np.maximum(df['sales_units'], 10)  # floor at 10\n",
    "    df['sales_revenue'] = df['sales_units'] * PRODUCT_COST\n",
    "    \n",
    "    # Encode channel as numeric\n",
    "    df['channel_online'] = (df['channel'] == 'online').astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04711087-8a8b-4130-af20-59861341f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 3. FEATURE ENGINEERING ====\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Prepare features for modeling:\n",
    "    - Scale continuous variables\n",
    "    - Create interaction terms (discount × channel, discount × weekend)\n",
    "    - Add lag features (previous day demand for cannibalization detection)\n",
    "    \"\"\"\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Interaction terms\n",
    "    df_feat['discount_x_online'] = df_feat['discount_pct'] * df_feat['channel_online']\n",
    "    df_feat['discount_x_weekend'] = df_feat['discount_pct'] * df_feat['is_weekend']\n",
    "    df_feat['discount_x_hour'] = df_feat['discount_pct'] * (df_feat['hour'] / 24.0)\n",
    "    \n",
    "    # Create lag demand (for cannibalization analysis)\n",
    "    df_feat['sales_lag1'] = df_feat['sales_units'].shift(1).fillna(df_feat['sales_units'].mean())\n",
    "    \n",
    "    # Polynomial features for non-linearity\n",
    "    df_feat['discount_sq'] = df_feat['discount_pct'] ** 2\n",
    "    df_feat['discount_cube'] = df_feat['discount_pct'] ** 3\n",
    "    \n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0101ef0d-f111-4ca5-a1bb-fb19e76e0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4. LINEAR BASELINE MODEL ====\n",
    "\n",
    "def train_linear_baseline(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fit simple linear regression as baseline for comparison.\n",
    "    Captures marginal effects but misses non-linearities & interactions.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"=== LINEAR BASELINE ===\")\n",
    "    print(f\"RMSE (train): {rmse_train:.2f}\")\n",
    "    print(f\"RMSE (test):  {rmse_test:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    return model, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3104311-d510-4bc7-b36d-53755a4736d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 5. NEURAL NETWORK MODEL ====\n",
    "\n",
    "def build_nn_model(input_dim):\n",
    "    \"\"\"\n",
    "    Build deep neural network for non-linear promotional effects.\n",
    "    Architecture: Input → Dense layers with ReLU → Output (linear)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(NN_HIDDEN_UNITS[0], activation='relu', input_dim=input_dim),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(NN_HIDDEN_UNITS[1], activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(NN_HIDDEN_UNITS[2], activation='relu'),\n",
    "        layers.Dense(1, activation='linear')  # Regression output\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=NN_LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_nn_model(X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train neural network with validation monitoring.\n",
    "    Returns model and training history.\n",
    "    \"\"\"\n",
    "    model = build_nn_model(X_train.shape[1])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=NN_EPOCHS,\n",
    "        batch_size=NN_BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    y_pred_test = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, model.predict(X_train, verbose=0).flatten()))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"=== NEURAL NETWORK MODEL ===\")\n",
    "    print(f\"RMSE (train): {rmse_train:.2f}\")\n",
    "    print(f\"RMSE (test):  {rmse_test:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    return model, y_pred_test, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3ab22f-84bf-4fbe-8cf9-3921f86f4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 6. BASELINE vs. UPLIFT MODELING ====\n",
    "\n",
    "def estimate_baseline_demand(model_nn, df_test):\n",
    "    \"\"\"\n",
    "    Estimate baseline (no promotion) demand by setting discount_pct = 0.\n",
    "    Compare vs. actual sales to isolate promotional lift.\n",
    "    \"\"\"\n",
    "    X_baseline = df_test.copy()\n",
    "    \n",
    "    # Zero out all discount-related features\n",
    "    discount_cols = [c for c in X_baseline.columns if 'discount' in c.lower()]\n",
    "    for col in discount_cols:\n",
    "        X_baseline[col] = 0.0\n",
    "    \n",
    "    baseline_pred = model_nn.predict(X_baseline, verbose=0).flatten()\n",
    "    return baseline_pred\n",
    "\n",
    "def calculate_uplift(actual_sales, baseline_pred, model_pred):\n",
    "    \"\"\"\n",
    "    Compute incremental lift:\n",
    "    - Gross Uplift = Actual - Baseline\n",
    "    - Net Uplift = Model Pred - Baseline (accounts for interaction effects)\n",
    "    \"\"\"\n",
    "    gross_uplift = actual_sales - baseline_pred\n",
    "    net_uplift = model_pred - baseline_pred\n",
    "    uplift_pct = (gross_uplift / baseline_pred) * 100\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'baseline': baseline_pred,\n",
    "        'model_pred': model_pred,\n",
    "        'actual': actual_sales,\n",
    "        'gross_uplift': gross_uplift,\n",
    "        'net_uplift': net_uplift,\n",
    "        'uplift_pct': uplift_pct\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc72c11f-80ce-41f7-a968-2bacbea0c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 7. INTERACTION EFFECTS ANALYSIS ====\n",
    "\n",
    "def analyze_interactions(df_test, uplift_df):\n",
    "    \"\"\"\n",
    "    Break down lift by discount × channel × timing combinations.\n",
    "    Shows which segments benefit most from promotions.\n",
    "    \"\"\"\n",
    "    results = df_test[['discount_pct', 'channel_online', 'is_weekend']].copy()\n",
    "    results['uplift_pct'] = uplift_df['uplift_pct']\n",
    "    \n",
    "    # Interaction by channel\n",
    "    print(\"=== INTERACTION EFFECTS ===\")\n",
    "    print(\"\\nBy Channel:\")\n",
    "    for channel in [0, 1]:\n",
    "        mask = results['channel_online'] == channel\n",
    "        avg_uplift = results[mask]['uplift_pct'].mean()\n",
    "        channel_name = 'Online' if channel == 1 else 'Retail'\n",
    "        print(f\"  {channel_name:8s}: {avg_uplift:6.2f}%\")\n",
    "    \n",
    "    # Interaction by discount level\n",
    "    print(\"\\nBy Discount Level:\")\n",
    "    results['discount_bin'] = pd.cut(results['discount_pct'], bins=3, labels=['Low', 'Med', 'High'])\n",
    "    for bin_name in ['Low', 'Med', 'High']:\n",
    "        mask = results['discount_bin'] == bin_name\n",
    "        avg_uplift = results[mask]['uplift_pct'].mean()\n",
    "        print(f\"  {bin_name:8s}: {avg_uplift:6.2f}%\")\n",
    "    \n",
    "    # Interaction by timing (weekend vs. weekday)\n",
    "    print(\"\\nBy Timing:\")\n",
    "    for is_wknd in [0, 1]:\n",
    "        mask = results['is_weekend'] == is_wknd\n",
    "        avg_uplift = results[mask]['uplift_pct'].mean()\n",
    "        timing_name = 'Weekend' if is_wknd == 1 else 'Weekday'\n",
    "        print(f\"  {timing_name:8s}: {avg_uplift:6.2f}%\")\n",
    "    \n",
    "    print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a5fee2-dc39-4667-b936-1f70aa53428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 8. CANNIBALIZATION DETECTION ====\n",
    "\n",
    "def detect_cannibalization(df_test, uplift_df):\n",
    "    \"\"\"\n",
    "    Flag potential cannibalization: high discount × is_weekend with negative uplift.\n",
    "    Cannibalization = promo on weekend steals sales from weekday.\n",
    "    \"\"\"\n",
    "    results = df_test[['discount_pct', 'is_weekend', 'sales_units']].copy()\n",
    "    results['uplift_pct'] = uplift_df['uplift_pct']\n",
    "    \n",
    "    # Identify high-discount weekend promos with poor uplift\n",
    "    cannibal_mask = (\n",
    "        (results['discount_pct'] > 25) &\n",
    "        (results['is_weekend'] == 1) &\n",
    "        (results['uplift_pct'] < CANNIBALIZATION_THRESHOLD * 100)\n",
    "    )\n",
    "    \n",
    "    cannibal_count = cannibal_mask.sum()\n",
    "    cannibal_avg_uplift = results[cannibal_mask]['uplift_pct'].mean() if cannibal_count > 0 else 0\n",
    "    \n",
    "    print(\"=== CANNIBALIZATION DETECTION ===\")\n",
    "    print(f\"High-discount weekend promos flagged: {cannibal_count}/{len(results)}\")\n",
    "    print(f\"Avg uplift (cannibalized): {cannibal_avg_uplift:.2f}%\")\n",
    "    print()\n",
    "    \n",
    "    return results[cannibal_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18fbed5-a2d2-4784-a4bf-1195081b9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 9. ROI & INCREMENTAL DEMAND ESTIMATION ====\n",
    "\n",
    "def calculate_promo_roi(df_test, uplift_df):\n",
    "    \"\"\"\n",
    "    Compute ROI per promotion:\n",
    "    - Gross Revenue = Uplift × Price\n",
    "    - Promo Cost = Discount Amount (foregone margin)\n",
    "    - Net Contribution = Gross Revenue - Promo Cost\n",
    "    - ROI = Net Contribution / Promo Cost\n",
    "    \"\"\"\n",
    "    roi_results = df_test[['discount_pct', 'sales_units', 'channel']].copy()\n",
    "    roi_results['baseline'] = uplift_df['baseline']\n",
    "    roi_results['uplift_units'] = uplift_df['gross_uplift']\n",
    "    \n",
    "    # Promo cost = discount applied to baseline volume\n",
    "    roi_results['promo_cost'] = (roi_results['baseline'] * roi_results['discount_pct'] / 100) * PRODUCT_COST\n",
    "    \n",
    "    # Incremental revenue = uplift × price\n",
    "    roi_results['incremental_revenue'] = roi_results['uplift_units'] * PRODUCT_COST\n",
    "    \n",
    "    # Net contribution (revenue - cost)\n",
    "    roi_results['net_contribution'] = roi_results['incremental_revenue'] - roi_results['promo_cost']\n",
    "    \n",
    "    # ROI = net / cost (avoid division by zero)\n",
    "    roi_results['roi'] = np.where(\n",
    "        roi_results['promo_cost'] > 1,\n",
    "        (roi_results['net_contribution'] / roi_results['promo_cost']) * 100,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    print(\"=== ROI & INCREMENTAL DEMAND ===\")\n",
    "    print(f\"Avg uplift units per promotion: {roi_results['uplift_units'].mean():.1f}\")\n",
    "    print(f\"Avg incremental revenue per promo: ${roi_results['incremental_revenue'].mean():.2f}\")\n",
    "    print(f\"Avg ROI: {roi_results['roi'].mean():.1f}%\")\n",
    "    \n",
    "    # ROI by channel\n",
    "    print(\"\\nROI by Channel:\")\n",
    "    for channel in ['online', 'retail']:\n",
    "        mask = roi_results['channel'] == channel\n",
    "        avg_roi = roi_results[mask]['roi'].mean()\n",
    "        print(f\"  {channel.capitalize():8s}: {avg_roi:6.1f}%\")\n",
    "    \n",
    "    print()\n",
    "    return roi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f43410b-ff52-4f19-8236-e7ddcf166421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 10. VISUALIZATION ====\n",
    "\n",
    "def plot_results(y_test, y_pred_linear, y_pred_nn, history):\n",
    "    \"\"\"\n",
    "    Compare model predictions and show training convergence.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Model comparison\n",
    "    axes[0, 0].scatter(y_test, y_pred_linear, alpha=0.5, label='Linear', s=20)\n",
    "    axes[0, 0].scatter(y_test, y_pred_nn, alpha=0.5, label='Neural Net', s=20)\n",
    "    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    axes[0, 0].set_xlabel('Actual Sales')\n",
    "    axes[0, 0].set_ylabel('Predicted Sales')\n",
    "    axes[0, 0].set_title('Model Predictions vs. Actual')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals: Linear\n",
    "    residuals_linear = y_test - y_pred_linear\n",
    "    axes[0, 1].scatter(y_pred_linear, residuals_linear, alpha=0.5, s=20)\n",
    "    axes[0, 1].axhline(0, color='r', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Sales (Linear)')\n",
    "    axes[0, 1].set_ylabel('Residuals')\n",
    "    axes[0, 1].set_title('Linear Model Residuals')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals: Neural Net\n",
    "    residuals_nn = y_test - y_pred_nn\n",
    "    axes[1, 0].scatter(y_pred_nn, residuals_nn, alpha=0.5, s=20)\n",
    "    axes[1, 0].axhline(0, color='r', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Predicted Sales (NN)')\n",
    "    axes[1, 0].set_ylabel('Residuals')\n",
    "    axes[1, 0].set_title('Neural Network Residuals')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training history\n",
    "    axes[1, 1].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[1, 1].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss (MSE)')\n",
    "    axes[1, 1].set_title('NN Training Convergence')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('promo_lift_results.png', dpi=100)\n",
    "    print(\"Plot saved to 'promo_lift_results.png'\\n\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b09765e-9e3c-4bec-a4e2-1310929a2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 11. MAIN PIPELINE ====\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    End-to-end promotional lift modeling:\n",
    "    1. Generate synthetic data\n",
    "    2. Feature engineering\n",
    "    3. Train linear & NN models\n",
    "    4. Compare baseline vs. uplift\n",
    "    5. Analyze interactions & cannibalization\n",
    "    6. Estimate ROI\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Generating promotion data...\")\n",
    "    df = generate_promotion_data(n_rows=500)\n",
    "    \n",
    "    print(\"Engineering features...\")\n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    feature_cols = [\n",
    "        'day_of_week', 'hour', 'channel_online', 'discount_pct',\n",
    "        'is_weekend', 'competitor_discount', 'inventory_level',\n",
    "        'discount_x_online', 'discount_x_weekend', 'discount_x_hour',\n",
    "        'sales_lag1', 'discount_sq', 'discount_cube'\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['sales_units'].values\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train-test-val split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=RANDOM_SEED\n",
    "    )\n",
    "    X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL TRAINING\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Linear baseline\n",
    "    model_linear, y_pred_linear = train_linear_baseline(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Neural network\n",
    "    model_nn, y_pred_nn, history = train_nn_model(\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"PROMOTIONAL ANALYSIS\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Reconstruct test data with original features for analysis\n",
    "    df_test = df.iloc[len(X_train) + len(X_val):len(X_train) + len(X_val) + len(X_test)].reset_index(drop=True)\n",
    "    \n",
    "    # Baseline vs uplift (NN predictions)\n",
    "    baseline_pred = estimate_baseline_demand(model_nn, df_test[feature_cols])\n",
    "    uplift_df = calculate_uplift(y_test, baseline_pred, y_pred_nn)\n",
    "    \n",
    "    print(\"Sample uplift breakdown (first 5 rows):\")\n",
    "    print(uplift_df.head())\n",
    "    print()\n",
    "    \n",
    "    # Interaction effects\n",
    "    interaction_results = analyze_interactions(df_test, uplift_df)\n",
    "    \n",
    "    # Cannibalization detection\n",
    "    cannibal_df = detect_cannibalization(df_test, uplift_df)\n",
    "    \n",
    "    # ROI calculation\n",
    "    roi_df = calculate_promo_roi(df_test, uplift_df)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"VISUALIZATION\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    plot_results(y_test, y_pred_linear, y_pred_nn, history)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"DONE\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # TODO: Experiment with changing discount distribution or cannibalization threshold\n",
    "    # and re-run to see how ROI and uplift shift. Try changing CANNIBALIZATION_THRESHOLD\n",
    "    # to -0.05 (more aggressive) or -0.15 (more lenient) and observe results.\n",
    "    \n",
    "    return model_nn, scaler, roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123ab001-0117-424f-986a-076d1ea1296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating promotion data...\n",
      "Engineering features...\n",
      "\n",
      "==================================================\n",
      "MODEL TRAINING\n",
      "==================================================\n",
      "\n",
      "=== LINEAR BASELINE ===\n",
      "RMSE (train): 9.69\n",
      "RMSE (test):  8.56\n",
      "\n",
      "=== NEURAL NETWORK MODEL ===\n",
      "RMSE (train): 10.30\n",
      "RMSE (test):  10.02\n",
      "\n",
      "==================================================\n",
      "PROMOTIONAL ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Sample uplift breakdown (first 5 rows):\n",
      "      baseline  model_pred      actual  gross_uplift   net_uplift  uplift_pct\n",
      "0  1756.620117   91.222252   84.474998  -1672.145119 -1665.397827  -95.191049\n",
      "1  1544.960938  107.017921  110.707853  -1434.253085 -1437.942993  -92.834262\n",
      "2  1558.845459   99.962936  117.214054  -1441.631405 -1458.882568  -92.480714\n",
      "3  1559.461304  117.281708  132.766296  -1426.695007 -1442.179565  -91.486400\n",
      "4  1783.564941   99.878113  101.787420  -1681.777521 -1683.686768  -94.293035\n",
      "\n",
      "=== INTERACTION EFFECTS ===\n",
      "\n",
      "By Channel:\n",
      "  Retail  : -93.01%\n",
      "  Online  : -92.88%\n",
      "\n",
      "By Discount Level:\n",
      "  Low     : -93.07%\n",
      "  Med     : -93.17%\n",
      "  High    : -92.58%\n",
      "\n",
      "By Timing:\n",
      "  Weekday : -92.71%\n",
      "  Weekend : -93.10%\n",
      "\n",
      "=== CANNIBALIZATION DETECTION ===\n",
      "High-discount weekend promos flagged: 23/75\n",
      "Avg uplift (cannibalized): -93.01%\n",
      "\n",
      "=== ROI & INCREMENTAL DEMAND ===\n",
      "Avg uplift units per promotion: -1501.4\n",
      "Avg incremental revenue per promo: $-22520.78\n",
      "Avg ROI: -763.3%\n",
      "\n",
      "ROI by Channel:\n",
      "  Online  : -716.0%\n",
      "  Retail  : -820.3%\n",
      "\n",
      "==================================================\n",
      "VISUALIZATION\n",
      "==================================================\n",
      "\n",
      "Plot saved to 'promo_lift_results.png'\n",
      "\n",
      "==================================================\n",
      "DONE\n",
      "==================================================\n",
      "\n",
      "\n",
      "✓ Promotion lift modeling complete!\n",
      "✓ Try changing NN_HIDDEN_UNITS, NN_EPOCHS, or discount thresholds to experiment.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_nn, scaler, roi_results = main()\n",
    "    print(\"\\n✓ Promotion lift modeling complete!\")\n",
    "    print(\"✓ Try changing NN_HIDDEN_UNITS, NN_EPOCHS, or discount thresholds to experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb6fc0-34b9-4143-9798-d7c78ad84b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
